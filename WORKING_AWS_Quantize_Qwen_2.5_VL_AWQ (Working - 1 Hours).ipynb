{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6225bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli --force-reinstall --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db07fef-7839-45a7-af3f-8ea18bc1d3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in c:\\users\\javia\\anaconda3\\lib\\site-packages (2.235.2)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: boto3<2.0,>=1.34.142 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.35.70)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (4.23.0)\n",
      "Collecting numpy<2.0,>=1.9.0 (from sagemaker)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (4.25.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (5.9.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.15 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.0.16)\n",
      "Requirement already satisfied: schema in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.26.20)\n",
      "Collecting botocore<1.36.0,>=1.35.70 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Using cached botocore-1.35.99-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.34.142->sagemaker) (0.10.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker) (2.10.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker) (13.9.4)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.15->sagemaker)\n",
      "  Using cached mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker) (0.21.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from docker->sagemaker) (308)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from requests->sagemaker) (2025.1.31)\n",
      "Requirement already satisfied: six in c:\\users\\javia\\anaconda3\\lib\\site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pandas->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Collecting dill>=0.3.9 (from pathos->sagemaker)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pox>=0.3.5 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Collecting multiprocess>=0.70.17 (from pathos->sagemaker)\n",
      "  Using cached multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\javia\\anaconda3\\lib\\site-packages (from tqdm->sagemaker) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (0.1.2)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Using cached botocore-1.35.99-py3-none-any.whl (13.3 MB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Using cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Using cached multiprocess-0.70.17-py39-none-any.whl (133 kB)\n",
      "Installing collected packages: numpy, mock, dill, attrs, multiprocess, botocore\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.1.0\n",
      "    Uninstalling attrs-25.1.0:\n",
      "      Successfully uninstalled attrs-25.1.0\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.36.24\n",
      "    Uninstalling botocore-1.36.24:\n",
      "      Successfully uninstalled botocore-1.36.24\n",
      "Successfully installed attrs-23.2.0 botocore-1.35.99 dill-0.3.9 mock-4.0.3 multiprocess-0.70.17 numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "doccano 1.8.4 requires chardet<5.0.0,>=4.0.0, which is not installed.\n",
      "doccano 1.8.4 requires SQLAlchemy<2.0.0,>=1.4.31, which is not installed.\n",
      "matplotlib 3.8.3 requires cycler>=0.10, which is not installed.\n",
      "matplotlib 3.8.3 requires fonttools>=4.22.0, which is not installed.\n",
      "matplotlib 3.8.3 requires kiwisolver>=1.3.1, which is not installed.\n",
      "matplotlib 3.8.3 requires pillow>=8, which is not installed.\n",
      "matplotlib 3.8.3 requires pyparsing>=2.3.1, which is not installed.\n",
      "mlflow 2.17.1 requires Flask<4, which is not installed.\n",
      "mlflow 2.17.1 requires markdown<4,>=3.3, which is not installed.\n",
      "mlflow 2.17.1 requires sqlalchemy<3,>=1.4.0, which is not installed.\n",
      "poetry 1.5.1 requires pexpect<5.0.0,>=4.7.0, which is not installed.\n",
      "ray 2.4.0 requires grpcio<=1.51.3,>=1.32.0; python_version < \"3.10\" and sys_platform != \"darwin\", which is not installed.\n",
      "ray 2.4.0 requires msgpack<2.0.0,>=1.0.0, which is not installed.\n",
      "scikit-learn 1.2.1 requires threadpoolctl>=2.0.0, which is not installed.\n",
      "torchvision 0.13.1 requires pillow!=8.3.*,>=5.3.0, which is not installed.\n",
      "trio 0.27.0 requires sortedcontainers, which is not installed.\n",
      "zero 0.9.1 requires tabulate>=0.8.2, which is not installed.\n",
      "datasets 3.3.1 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\n",
      "datasets 3.3.1 requires multiprocess<0.70.17, but you have multiprocess 0.70.17 which is incompatible.\n",
      "awscli 1.37.24 requires botocore==1.36.24, but you have botocore 1.35.99 which is incompatible.\n",
      "awscli 1.37.24 requires s3transfer<0.12.0,>=0.11.0, but you have s3transfer 0.10.4 which is incompatible.\n",
      "copulas 0.7.0 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "ctgan 0.5.2 requires packaging<22,>=20, but you have packaging 24.2 which is incompatible.\n",
      "ctgan 0.5.2 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "ctgan 0.5.2 requires torch<2,>=1.8.0, but you have torch 2.3.1 which is incompatible.\n",
      "deepecho 0.3.0.post1 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "deepecho 0.3.0.post1 requires torch<2,>=1.8.0, but you have torch 2.3.1 which is incompatible.\n",
      "doccano 1.8.4 requires pandas<2.0.0,>=1.4.2, but you have pandas 2.2.3 which is incompatible.\n",
      "github 1.2.7 requires aiohttp==3.8.1, but you have aiohttp 3.11.12 which is incompatible.\n",
      "mlflow 2.17.1 requires pyarrow<18,>=4.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "poetry 1.5.1 requires platformdirs<4.0.0,>=3.0.0, but you have platformdirs 4.3.6 which is incompatible.\n",
      "poetry 1.5.1 requires virtualenv<21.0.0,>=20.22.0, but you have virtualenv 20.21.0 which is incompatible.\n",
      "rdt 1.2.1 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "rdt 1.2.1 requires pyyaml<6,>=5.4.1, but you have pyyaml 6.0.2 which is incompatible.\n",
      "rdt 1.2.1 requires scipy<1.8,>=1.5.4, but you have scipy 1.12.0 which is incompatible.\n",
      "sdmetrics 0.7.0 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "sdmetrics 0.7.0 requires torch<2,>=1.8.0, but you have torch 2.3.1 which is incompatible.\n",
      "sdv 0.17.1 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "spacy 3.0.9 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 2.10.2 which is incompatible.\n",
      "spacy 3.0.9 requires typer<0.4.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 2.10.2 which is incompatible.\n",
      "torchvision 0.13.1 requires torch==1.12.1, but you have torch 2.3.1 which is incompatible.\n",
      "zero 0.9.1 requires Click==7.0, but you have click 8.1.7 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a86303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: boto3 in c:\\users\\javia\\anaconda3\\lib\\site-packages (1.35.70)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.70 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3) (1.35.99)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3) (0.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from botocore<1.36.0,>=1.35.70->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from botocore<1.36.0,>=1.35.70->boto3) (1.26.20)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.70->boto3) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837fa62-7d6d-4876-8ada-9efd14bd6468",
   "metadata": {},
   "source": [
    "#### First attempt of ChartQA based quantization to AWQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adb46135-918e-483d-b187-84410be973bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"YOUR_AWS_ROLE\"\n",
    "bucket_name = \"llama-training-s3\"\n",
    "s3_prefix = \"llama-training-s3/quantized\"\n",
    "s3_output_path=f\"s3://{bucket_name}/{s3_prefix}/model\"\n",
    "hf_token=\"YOUR_HF_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a0f04-6aa5-40a5-819a-790a8ae47de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir training_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3606f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_code/requirements.txt\n",
    "boto3\n",
    "transformers\n",
    "torch\n",
    "datasets\n",
    "accelerate\n",
    "sentencepiece\n",
    "bitsandbytes\n",
    "peft\n",
    "pyarrow\n",
    "deepspeed\n",
    "accelerate\n",
    "autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ed53695-88ce-48b7-8e89-33cbf33b207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_code/quantize_llm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_code/quantize_llm.py\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from transformers import AutoTokenizer\n",
    "import boto3\n",
    "import sys\n",
    "\n",
    "\n",
    "if not os.path.exists(\"AutoAWQ\"):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/casper-hansen/AutoAWQ.git\"], check=True)\n",
    "\n",
    "# Install AutoAWQ from the cloned repository in editable mode (this runs setup.py)\n",
    "# Use an absolute path to ensure correct installation\n",
    "autoawq_path = os.path.join(os.getcwd(), \"AutoAWQ\")\n",
    "subprocess.run([\"pip\", \"install\", \"-e\", autoawq_path], check=True)\n",
    "\n",
    "# Add the cloned repository to PYTHONPATH manually in case it's not discovered\n",
    "sys.path.insert(0, autoawq_path)\n",
    "\n",
    "# Install additional dependencies\n",
    "subprocess.run([\"pip\", \"install\", \"boto3\"], check=True)\n",
    "subprocess.run([\"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"transformers==4.50.3\"], check=True)\n",
    "\n",
    "\n",
    "role = \"YOUR_AWS_ROLE\"\n",
    "bucket_name = \"llama-training-s3\"\n",
    "s3_prefix = \"llama-training-s3/quantized\"\n",
    "\n",
    "\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from awq import AutoAWQForCausalLM\n",
    "from awq.utils.qwen_vl_utils import process_vision_info\n",
    "from awq.quantize.quantizer import AwqQuantizer, clear_memory, get_best_device\n",
    "\n",
    "\n",
    "\n",
    "# Parse arguments (S3 bucket and model path)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"javiagu/Qwen-2.5-ChartQA\")\n",
    "parser.add_argument(\"--quant_path\", type=str, default=\"/opt/ml/model/Qwen-2.5-ChartQA\")\n",
    "parser.add_argument(\"--s3_output\", type=str, required=True, help=\"S3 path to upload quantized model\")\n",
    "parser.add_argument(\"--hf_token\", type=str, required=True, help=\"Hugging Face authentication token\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Specify paths and hyperparameters for quantization\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\"}\n",
    "\n",
    "# Load the model\n",
    "model = AutoAWQForCausalLM.from_pretrained(\n",
    "    args.model_path, attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "# Ensure the tokenizer uses left padding\n",
    "model.processor.tokenizer.padding_side = 'left'\n",
    "\n",
    "# Custom quantizer definition remains the same\n",
    "class Qwen2VLAwqQuantizer(AwqQuantizer):\n",
    "    def init_quant(self, n_samples=None, max_seq_len=None):\n",
    "        modules = self.awq_model.get_model_layers(self.model)\n",
    "        print(\"Number of layers to calibrate:\", len(modules))\n",
    "        print(\"First module before patching:\", modules[0])\n",
    "\n",
    "        samples = self.calib_data\n",
    "\n",
    "        inps = []\n",
    "        layer_kwargs = {}\n",
    "\n",
    "        best_device = get_best_device()\n",
    "        modules[0] = modules[0].to(best_device)\n",
    "        self.awq_model.move_embed(self.model, best_device)\n",
    "\n",
    "        # Patch layer 0 to capture input and kwargs.\n",
    "        class Catcher(nn.Module):\n",
    "            def __init__(self, module):\n",
    "                super().__init__()\n",
    "                self.module = module\n",
    "\n",
    "            def forward(self, *args, **kwargs):\n",
    "                # Assume first input to forward is hidden states.\n",
    "                ### Debugging\n",
    "                print(\"------------------\")\n",
    "                print(\"Catcher triggered!\")\n",
    "                print(\"------------------\")\n",
    "                ### Debugging End\n",
    "                \n",
    "                if len(args) > 0:\n",
    "                    hidden_states = args[0]\n",
    "                else:\n",
    "                    first_key = list(kwargs.keys())[0]\n",
    "                    hidden_states = kwargs.pop(first_key)\n",
    "                inps.append(hidden_states)\n",
    "                layer_kwargs.update(kwargs)\n",
    "                raise ValueError  # early exit to break later inference\n",
    "\n",
    "        def move_to_device(obj, device):\n",
    "            def get_device(obj):\n",
    "                if isinstance(obj, torch.Tensor):\n",
    "                    return obj.device\n",
    "                return next(obj.parameters()).device\n",
    "            if get_device(obj) != device:\n",
    "                obj = obj.to(device)\n",
    "            return obj\n",
    "\n",
    "        modules[0] = Catcher(modules[0])\n",
    "        for k, v in samples.items():\n",
    "            if isinstance(v, (torch.Tensor, nn.Module)):\n",
    "                samples[k] = move_to_device(v, best_device)\n",
    "        try:\n",
    "            self.model(**samples)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        finally:\n",
    "            for k, v in samples.items():\n",
    "                if isinstance(v, (torch.Tensor, nn.Module)):\n",
    "                    samples[k] = move_to_device(v, \"cpu\")\n",
    "        modules[0] = modules[0].module  # restore original module\n",
    "\n",
    "        del samples\n",
    "        inps = inps[0]\n",
    "\n",
    "        modules[0] = modules[0].cpu()\n",
    "        self.awq_model.move_embed(self.model, \"cpu\")\n",
    "\n",
    "        clear_memory()\n",
    "\n",
    "        return modules, layer_kwargs, inps\n",
    "\n",
    "# ----------------- Prepare Calibration Data -----------------\n",
    "# Load and format the ChartQA dataset (or your own dataset)\n",
    "dataset_id = \"HuggingFaceM4/ChartQA\"\n",
    "raw_eval_dataset = load_dataset(dataset_id, split=\"val[:1%]\")\n",
    "\n",
    "system_message = (\n",
    "    \"You are a Vision Language Model specialized in interpreting visual data from chart images.\\n\"\n",
    "    \"Your task is to analyze the provided chart image and respond to queries with concise answers, \"\n",
    "    \"usually a single word, number, or short phrase.\\n\"\n",
    "    \"The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\\n\"\n",
    "    \"Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\n",
    ")\n",
    "\n",
    "def format_data(sample):\n",
    "    label_text = sample[\"label\"][0] if isinstance(sample[\"label\"], list) else sample[\"label\"]\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]},\n",
    "                {\"type\": \"text\", \"text\": sample[\"query\"]},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": label_text}],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "# Format the evaluation dataset for calibration.\n",
    "calib_dataset = [format_data(sample) for sample in raw_eval_dataset]\n",
    "\n",
    "print(\"Total calibration samples:\", len(calib_dataset))\n",
    "print(\"First calibration sample:\")\n",
    "print(calib_dataset[0])\n",
    "\n",
    "\n",
    "# Process the dataset into tensors for calibration.\n",
    "# Note: Unlike training, we only need the inputs, not labels.\n",
    "text = model.processor.apply_chat_template(calib_dataset, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(calib_dataset)\n",
    "calib_inputs = model.processor(\n",
    "    text=text, images=image_inputs, videos=video_inputs, padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "calib_inputs = {key: tensor.to(\"cuda\") for key, tensor in calib_inputs.items()}\n",
    "\n",
    "\n",
    "### Debugging\n",
    "print(\"------------------------------\")\n",
    "print(\"Checking Calibration Content: \")\n",
    "print(\"------------------------------\")\n",
    "# After obtaining calib_inputs\n",
    "print(\"Calibration Data Summary:\")\n",
    "for key, tensor in calib_inputs.items():\n",
    "    # Move tensor to CPU and convert to list for safe printing (if needed)\n",
    "    tensor_cpu = tensor.detach().cpu()\n",
    "    print(f\"{key}: shape={tensor_cpu.shape}\")\n",
    "    # Print the first 5 elements of the tensor (adjust as needed)\n",
    "    # This assumes the tensor is at least 1-dimensional.\n",
    "    try:\n",
    "        # If it's a multi-dimensional tensor, you can print the first sample.\n",
    "        print(f\"  Sample data: {tensor_cpu[0].tolist()[:10]}\")  \n",
    "    except Exception as e:\n",
    "        print(f\"  Could not print sample data: {e}\")\n",
    "### Debugging End\n",
    "\n",
    "### Debugging\n",
    "#try:\n",
    "#    with torch.no_grad():\n",
    "#        output = model(**calib_inputs)\n",
    "#        print(\"Forward pass completed, output shape:\", output.shape)\n",
    "#except Exception as e:\n",
    "#    print(\"Forward pass error:\", e)\n",
    "### Debugging End\n",
    "\n",
    "# Perform quantization\n",
    "print(\"Quantizing model...\")\n",
    "model.quantize(calib_data=calib_inputs, quant_config=quant_config, quantizer_cls=Qwen2VLAwqQuantizer)\n",
    "\n",
    "# Enable cache before saving the quantized model.\n",
    "model.model.config.use_cache = model.model.generation_config.use_cache = True\n",
    "model.save_quantized(args.quant_path, safetensors=True, shard_size=\"4GB\")\n",
    "\n",
    "# Save quantized model locally\n",
    "print(f\"Saving quantized model at {args.quant_path}...\")\n",
    "model.save_quantized(args.quant_path)\n",
    "\n",
    "tokenizer = model.processor.tokenizer\n",
    "tokenizer.save_pretrained(args.quant_path)\n",
    "\n",
    "# Upload to S3 for downloading later\n",
    "print(f\"Uploading quantized model to {args.s3_output}...\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket_name, prefix = args.s3_output.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "for root, _, files in os.walk(args.quant_path):\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        s3_path = os.path.join(prefix, os.path.relpath(local_path, args.quant_path))\n",
    "        print(f\"Uploading {local_path} to s3://{bucket_name}/{s3_prefix}\")\n",
    "        s3_client.upload_file(local_path, bucket_name, s3_prefix)\n",
    "\n",
    "print(\"Quantization complete and uploaded to S3.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfd5cb-d2e9-4b5c-8c7d-a2cb82fc88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"quantize_llm.py\",\n",
    "    source_dir=\"training_code\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4de.24xlarge\",#\"ml.g5.4xlarge\",  # Change based on needs\n",
    "    framework_version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    hyperparameters={\n",
    "        \"s3_output\": s3_output_path,\n",
    "        \"hf_token\": hf_token  # Add your Hugging Face token here\n",
    "    },\n",
    "    output_path=s3_output_path\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "estimator.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf79478-ca56-4a8c-be5d-c31b2e472a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57503cc7-0a13-407e-94e5-78e955b9a029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d80c98-46ac-4cd6-8627-c70b76699079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e35065-8c16-4f3d-a5cb-acf281d4c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker stop-training-job --training-job-name pytorch-training-2025-04-01-06-21-06-319"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
