{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6225bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli --force-reinstall --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db07fef-7839-45a7-af3f-8ea18bc1d3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in c:\\users\\javia\\anaconda3\\lib\\site-packages (2.235.2)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: boto3<2.0,>=1.34.142 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.35.70)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (4.23.0)\n",
      "Collecting numpy<2.0,>=1.9.0 (from sagemaker)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (4.25.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (5.9.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.15 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.0.16)\n",
      "Requirement already satisfied: schema in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker) (1.26.20)\n",
      "Collecting botocore<1.36.0,>=1.35.70 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Using cached botocore-1.35.99-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3<2.0,>=1.34.142->sagemaker) (0.10.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker) (2.10.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker) (13.9.4)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.15->sagemaker)\n",
      "  Using cached mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker) (0.21.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from docker->sagemaker) (308)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from requests->sagemaker) (2025.1.31)\n",
      "Requirement already satisfied: six in c:\\users\\javia\\anaconda3\\lib\\site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pandas->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Collecting dill>=0.3.9 (from pathos->sagemaker)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pox>=0.3.5 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Collecting multiprocess>=0.70.17 (from pathos->sagemaker)\n",
      "  Using cached multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\javia\\anaconda3\\lib\\site-packages (from tqdm->sagemaker) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\javia\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker) (0.1.2)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Using cached botocore-1.35.99-py3-none-any.whl (13.3 MB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Using cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Using cached multiprocess-0.70.17-py39-none-any.whl (133 kB)\n",
      "Installing collected packages: numpy, mock, dill, attrs, multiprocess, botocore\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.1.0\n",
      "    Uninstalling attrs-25.1.0:\n",
      "      Successfully uninstalled attrs-25.1.0\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.36.24\n",
      "    Uninstalling botocore-1.36.24:\n",
      "      Successfully uninstalled botocore-1.36.24\n",
      "Successfully installed attrs-23.2.0 botocore-1.35.99 dill-0.3.9 mock-4.0.3 multiprocess-0.70.17 numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "doccano 1.8.4 requires chardet<5.0.0,>=4.0.0, which is not installed.\n",
      "doccano 1.8.4 requires SQLAlchemy<2.0.0,>=1.4.31, which is not installed.\n",
      "matplotlib 3.8.3 requires cycler>=0.10, which is not installed.\n",
      "matplotlib 3.8.3 requires fonttools>=4.22.0, which is not installed.\n",
      "matplotlib 3.8.3 requires kiwisolver>=1.3.1, which is not installed.\n",
      "matplotlib 3.8.3 requires pillow>=8, which is not installed.\n",
      "matplotlib 3.8.3 requires pyparsing>=2.3.1, which is not installed.\n",
      "mlflow 2.17.1 requires Flask<4, which is not installed.\n",
      "mlflow 2.17.1 requires markdown<4,>=3.3, which is not installed.\n",
      "mlflow 2.17.1 requires sqlalchemy<3,>=1.4.0, which is not installed.\n",
      "poetry 1.5.1 requires pexpect<5.0.0,>=4.7.0, which is not installed.\n",
      "ray 2.4.0 requires grpcio<=1.51.3,>=1.32.0; python_version < \"3.10\" and sys_platform != \"darwin\", which is not installed.\n",
      "ray 2.4.0 requires msgpack<2.0.0,>=1.0.0, which is not installed.\n",
      "scikit-learn 1.2.1 requires threadpoolctl>=2.0.0, which is not installed.\n",
      "torchvision 0.13.1 requires pillow!=8.3.*,>=5.3.0, which is not installed.\n",
      "trio 0.27.0 requires sortedcontainers, which is not installed.\n",
      "zero 0.9.1 requires tabulate>=0.8.2, which is not installed.\n",
      "datasets 3.3.1 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\n",
      "datasets 3.3.1 requires multiprocess<0.70.17, but you have multiprocess 0.70.17 which is incompatible.\n",
      "awscli 1.37.24 requires botocore==1.36.24, but you have botocore 1.35.99 which is incompatible.\n",
      "awscli 1.37.24 requires s3transfer<0.12.0,>=0.11.0, but you have s3transfer 0.10.4 which is incompatible.\n",
      "copulas 0.7.0 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "ctgan 0.5.2 requires packaging<22,>=20, but you have packaging 24.2 which is incompatible.\n",
      "ctgan 0.5.2 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "ctgan 0.5.2 requires torch<2,>=1.8.0, but you have torch 2.3.1 which is incompatible.\n",
      "deepecho 0.3.0.post1 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "deepecho 0.3.0.post1 requires torch<2,>=1.8.0, but you have torch 2.3.1 which is incompatible.\n",
      "doccano 1.8.4 requires pandas<2.0.0,>=1.4.2, but you have pandas 2.2.3 which is incompatible.\n",
      "github 1.2.7 requires aiohttp==3.8.1, but you have aiohttp 3.11.12 which is incompatible.\n",
      "mlflow 2.17.1 requires pyarrow<18,>=4.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "poetry 1.5.1 requires platformdirs<4.0.0,>=3.0.0, but you have platformdirs 4.3.6 which is incompatible.\n",
      "poetry 1.5.1 requires virtualenv<21.0.0,>=20.22.0, but you have virtualenv 20.21.0 which is incompatible.\n",
      "rdt 1.2.1 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "rdt 1.2.1 requires pyyaml<6,>=5.4.1, but you have pyyaml 6.0.2 which is incompatible.\n",
      "rdt 1.2.1 requires scipy<1.8,>=1.5.4, but you have scipy 1.12.0 which is incompatible.\n",
      "sdmetrics 0.7.0 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "sdmetrics 0.7.0 requires torch<2,>=1.8.0, but you have torch 2.3.1 which is incompatible.\n",
      "sdv 0.17.1 requires pandas<2,>=1.1.3, but you have pandas 2.2.3 which is incompatible.\n",
      "spacy 3.0.9 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 2.10.2 which is incompatible.\n",
      "spacy 3.0.9 requires typer<0.4.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 2.10.2 which is incompatible.\n",
      "torchvision 0.13.1 requires torch==1.12.1, but you have torch 2.3.1 which is incompatible.\n",
      "zero 0.9.1 requires Click==7.0, but you have click 8.1.7 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a86303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: boto3 in c:\\users\\javia\\anaconda3\\lib\\site-packages (1.35.70)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.70 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3) (1.35.99)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from boto3) (0.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from botocore<1.36.0,>=1.35.70->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from botocore<1.36.0,>=1.35.70->boto3) (1.26.20)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\javia\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.70->boto3) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837fa62-7d6d-4876-8ada-9efd14bd6468",
   "metadata": {},
   "source": [
    "#### First attempt of ChartQA based quantization to AWQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb46135-918e-483d-b187-84410be973bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"AWS_ROLE_API_KEY\"\n",
    "bucket_name = \"llama-training-s3\"\n",
    "s3_prefix = \"llama-training-s3/quantized\"\n",
    "s3_output_path=f\"s3://{bucket_name}/{s3_prefix}/model\"\n",
    "hf_token=\"HUGGINGFACE_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f49a0f04-6aa5-40a5-819a-790a8ae47de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 training_code이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "%mkdir training_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3606f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_code/requirements.txt\n",
    "boto3\n",
    "transformers\n",
    "torch\n",
    "datasets\n",
    "accelerate\n",
    "sentencepiece\n",
    "bitsandbytes\n",
    "peft\n",
    "pyarrow\n",
    "deepspeed\n",
    "accelerate\n",
    "autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ed53695-88ce-48b7-8e89-33cbf33b207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_code/quantize_llm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_code/quantize_llm.py\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from transformers import AutoTokenizer\n",
    "import boto3\n",
    "import sys\n",
    "\n",
    "\n",
    "if not os.path.exists(\"AutoAWQ\"):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/casper-hansen/AutoAWQ.git\"], check=True)\n",
    "\n",
    "# Install AutoAWQ from the cloned repository in editable mode (this runs setup.py)\n",
    "# Use an absolute path to ensure correct installation\n",
    "autoawq_path = os.path.join(os.getcwd(), \"AutoAWQ\")\n",
    "subprocess.run([\"pip\", \"install\", \"-e\", autoawq_path], check=True)\n",
    "\n",
    "# Add the cloned repository to PYTHONPATH manually in case it's not discovered\n",
    "sys.path.insert(0, autoawq_path)\n",
    "\n",
    "# Install additional dependencies\n",
    "subprocess.run([\"pip\", \"install\", \"boto3\"], check=True)\n",
    "subprocess.run([\"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"transformers==4.50.3\"], check=True)\n",
    "\n",
    "\n",
    "role = \"AWS_ROLE_API_KEY\"\n",
    "bucket_name = \"llama-training-s3\"\n",
    "s3_prefix = \"llama-training-s3/quantized\"\n",
    "\n",
    "\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from awq import AutoAWQForCausalLM\n",
    "from awq.utils.qwen_vl_utils import process_vision_info\n",
    "from awq.quantize.quantizer import AwqQuantizer, clear_memory, get_best_device\n",
    "\n",
    "\n",
    "\n",
    "# Parse arguments (S3 bucket and model path)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"javiagu/Qwen-2.5-CPPE-5\")\n",
    "parser.add_argument(\"--quant_path\", type=str, default=\"/opt/ml/model/Qwen-2.5-CPPE-5\")\n",
    "parser.add_argument(\"--s3_output\", type=str, required=True, help=\"S3 path to upload quantized model\")\n",
    "parser.add_argument(\"--hf_token\", type=str, required=True, help=\"Hugging Face authentication token\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Specify paths and hyperparameters for quantization\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\"}\n",
    "\n",
    "# Load the model\n",
    "model = AutoAWQForCausalLM.from_pretrained(\n",
    "    args.model_path, attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "# Ensure the tokenizer uses left padding\n",
    "model.processor.tokenizer.padding_side = 'left'\n",
    "\n",
    "# Custom quantizer definition remains the same\n",
    "class Qwen2VLAwqQuantizer(AwqQuantizer):\n",
    "    def init_quant(self, n_samples=None, max_seq_len=None):\n",
    "        modules = self.awq_model.get_model_layers(self.model)\n",
    "        print(\"Number of layers to calibrate:\", len(modules))\n",
    "        print(\"First module before patching:\", modules[0])\n",
    "\n",
    "        samples = self.calib_data\n",
    "\n",
    "        inps = []\n",
    "        layer_kwargs = {}\n",
    "\n",
    "        best_device = get_best_device()\n",
    "        modules[0] = modules[0].to(best_device)\n",
    "        self.awq_model.move_embed(self.model, best_device)\n",
    "\n",
    "        # Patch layer 0 to capture input and kwargs.\n",
    "        class Catcher(nn.Module):\n",
    "            def __init__(self, module):\n",
    "                super().__init__()\n",
    "                self.module = module\n",
    "\n",
    "            def forward(self, *args, **kwargs):\n",
    "                # Assume first input to forward is hidden states.\n",
    "                ### Debugging\n",
    "                print(\"------------------\")\n",
    "                print(\"Catcher triggered!\")\n",
    "                print(\"------------------\")\n",
    "                ### Debugging End\n",
    "                \n",
    "                if len(args) > 0:\n",
    "                    hidden_states = args[0]\n",
    "                else:\n",
    "                    first_key = list(kwargs.keys())[0]\n",
    "                    hidden_states = kwargs.pop(first_key)\n",
    "                inps.append(hidden_states)\n",
    "                layer_kwargs.update(kwargs)\n",
    "                raise ValueError  # early exit to break later inference\n",
    "\n",
    "        def move_to_device(obj, device):\n",
    "            def get_device(obj):\n",
    "                if isinstance(obj, torch.Tensor):\n",
    "                    return obj.device\n",
    "                return next(obj.parameters()).device\n",
    "            if get_device(obj) != device:\n",
    "                obj = obj.to(device)\n",
    "            return obj\n",
    "\n",
    "        modules[0] = Catcher(modules[0])\n",
    "        for k, v in samples.items():\n",
    "            if isinstance(v, (torch.Tensor, nn.Module)):\n",
    "                samples[k] = move_to_device(v, best_device)\n",
    "        try:\n",
    "            self.model(**samples)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        finally:\n",
    "            for k, v in samples.items():\n",
    "                if isinstance(v, (torch.Tensor, nn.Module)):\n",
    "                    samples[k] = move_to_device(v, \"cpu\")\n",
    "        modules[0] = modules[0].module  # restore original module\n",
    "\n",
    "        del samples\n",
    "        inps = inps[0]\n",
    "\n",
    "        modules[0] = modules[0].cpu()\n",
    "        self.awq_model.move_embed(self.model, \"cpu\")\n",
    "\n",
    "        clear_memory()\n",
    "\n",
    "        return modules, layer_kwargs, inps\n",
    "\n",
    "# ----------------- Prepare Calibration Data -----------------\n",
    "# Load and format the ChartQA dataset (or your own dataset)\n",
    "dataset_id = \"rishitdagli/cppe-5\"\n",
    "raw_train_dataset = load_dataset(dataset_id, split=\"train[:10%]\")\n",
    "\n",
    "# Define a filter function that checks image dimensions.\n",
    "def filter_by_image_size(example):\n",
    "    # The image can be stored as a dict with metadata (e.g., width, height) or as a PIL Image.\n",
    "    image_data = example[\"image\"]\n",
    "    \n",
    "    # If metadata exists, use it.\n",
    "    if isinstance(image_data, dict):\n",
    "        width = image_data.get(\"width\")\n",
    "        height = image_data.get(\"height\")\n",
    "        # If for some reason the dimensions are missing, load the image header to get the size.\n",
    "        if width is None or height is None:\n",
    "            with Image.open(image_data[\"path\"]) as img:\n",
    "                width, height = img.size\n",
    "    else:\n",
    "        # Assume image_data is a PIL.Image\n",
    "        width, height = image_data.size\n",
    "\n",
    "    # Only keep images with width <= 600 and height <= 640.\n",
    "    return width <= 600 and height <= 600\n",
    "\n",
    "raw_train_dataset = raw_train_dataset.filter(filter_by_image_size)\n",
    "\n",
    "print(\"\\nFirst item from the train split:\")\n",
    "print(raw_train_dataset[0])\n",
    "\n",
    "# Define the system message for the chatbot-style interaction.\n",
    "system_message = (\n",
    "    \"Your task will be he predefined main task.\\n\"\n",
    ")\n",
    "\n",
    "def format_data(sample):\n",
    "    # Ensure the label is in string format (if provided as a list, take the first element)\n",
    "    label_text = sample[\"objects\"][0] if isinstance(sample[\"objects\"], list) else sample[\"objects\"]\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": sample[\"image\"],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Please, perform the main task:\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": label_text}],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "# Format the evaluation dataset for calibration.\n",
    "calib_dataset = [format_data(sample) for sample in raw_train_dataset]\n",
    "\n",
    "print(\"Total calibration samples:\", len(calib_dataset))\n",
    "print(\"First calibration sample:\")\n",
    "print(calib_dataset[0])\n",
    "\n",
    "\n",
    "# Process the dataset into tensors for calibration.\n",
    "# Note: Unlike training, we only need the inputs, not labels.\n",
    "text = model.processor.apply_chat_template(calib_dataset, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(calib_dataset)\n",
    "calib_inputs = model.processor(\n",
    "    text=text, images=image_inputs, videos=video_inputs, padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "calib_inputs = {key: tensor.to(\"cuda\") for key, tensor in calib_inputs.items()}\n",
    "\n",
    "\n",
    "### Debugging\n",
    "print(\"------------------------------\")\n",
    "print(\"Checking Calibration Content: \")\n",
    "print(\"------------------------------\")\n",
    "# After obtaining calib_inputs\n",
    "print(\"Calibration Data Summary:\")\n",
    "for key, tensor in calib_inputs.items():\n",
    "    # Move tensor to CPU and convert to list for safe printing (if needed)\n",
    "    tensor_cpu = tensor.detach().cpu()\n",
    "    print(f\"{key}: shape={tensor_cpu.shape}\")\n",
    "    # Print the first 5 elements of the tensor (adjust as needed)\n",
    "    # This assumes the tensor is at least 1-dimensional.\n",
    "    try:\n",
    "        # If it's a multi-dimensional tensor, you can print the first sample.\n",
    "        print(f\"  Sample data: {tensor_cpu[0].tolist()[:10]}\")  \n",
    "    except Exception as e:\n",
    "        print(f\"  Could not print sample data: {e}\")\n",
    "### Debugging End\n",
    "\n",
    "### Debugging\n",
    "#try:\n",
    "#    with torch.no_grad():\n",
    "#        output = model(**calib_inputs)\n",
    "#        print(\"Forward pass completed, output shape:\", output.shape)\n",
    "#except Exception as e:\n",
    "#    print(\"Forward pass error:\", e)\n",
    "### Debugging End\n",
    "\n",
    "# Perform quantization\n",
    "print(\"Quantizing model...\")\n",
    "model.quantize(calib_data=calib_inputs, quant_config=quant_config, quantizer_cls=Qwen2VLAwqQuantizer)\n",
    "\n",
    "# Enable cache before saving the quantized model.\n",
    "model.model.config.use_cache = model.model.generation_config.use_cache = True\n",
    "model.save_quantized(args.quant_path, safetensors=True, shard_size=\"4GB\")\n",
    "\n",
    "# Save quantized model locally\n",
    "print(f\"Saving quantized model at {args.quant_path}...\")\n",
    "model.save_quantized(args.quant_path)\n",
    "\n",
    "tokenizer = model.processor.tokenizer\n",
    "tokenizer.save_pretrained(args.quant_path)\n",
    "\n",
    "# Upload to S3 for downloading later\n",
    "print(f\"Uploading quantized model to {args.s3_output}...\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket_name, prefix = args.s3_output.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "for root, _, files in os.walk(args.quant_path):\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        s3_path = os.path.join(prefix, os.path.relpath(local_path, args.quant_path))\n",
    "        print(f\"Uploading {local_path} to s3://{bucket_name}/{s3_prefix}\")\n",
    "        s3_client.upload_file(local_path, bucket_name, s3_prefix)\n",
    "\n",
    "print(\"Quantization complete and uploaded to S3.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cbfd5cb-d2e9-4b5c-8c7d-a2cb82fc88eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/04/25 15:48:21] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/04/25 15:48:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=827646;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=976606;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\telemetry\\telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py#681\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">681</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=634266;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=868493;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py#681\u001b\\\u001b[2m681\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/04/25 15:48:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> image_uri is not presented, retrieving image_uri based on            <a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py#681\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">681</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         instance_type, framework etc.                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/04/25 15:48:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m image_uri is not presented, retrieving image_uri based on            \u001b]8;id=462742;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=791118;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\image_uris.py#681\u001b\\\u001b[2m681\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         instance_type, framework etc.                                        \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/04/25 15:48:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pytorch-training-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-04-06-48-21-030                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/04/25 15:48:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=958284;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=569494;file://C:\\Users\\user\\anaconda3\\lib\\site-packages\\sagemaker\\session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         pytorch-training-\u001b[1;36m2025\u001b[0m-04-04-06-48-21-030                               \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-04 06:48:29 Starting - Starting the training job\n",
      "2025-04-04 06:48:29 Pending - Training job waiting for capacity...\n",
      "2025-04-04 06:49:12 Pending - Preparing the instances for training.....................\n",
      "2025-04-04 06:53:00 Downloading - Downloading the training image.....................\n",
      "2025-04-04 06:56:42 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 550.144.03\u001b[0m\n",
      "\u001b[34mCurrent installed NVIDIA driver version is 550.144.03\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[34m2025-04-04 06:57:41,507 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-04-04 06:57:41,624 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-04 06:57:41,631 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-04-04 06:57:41,633 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-04-04 06:57:43,081 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34mCollecting datasets (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.5.1)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (19.0.1)\u001b[0m\n",
      "\u001b[34mCollecting deepspeed==0.15.4 (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading deepspeed-0.15.4.tar.gz (1.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 11.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (11.1.0)\u001b[0m\n",
      "\u001b[34mCollecting qwen_vl_utils (from -r requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34mDownloading qwen_vl_utils-0.0.10-py3-none-any.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting hjson (from deepspeed==0.15.4->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting msgpack (from deepspeed==0.15.4->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting ninja (from deepspeed==0.15.4->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 10)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 10)) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 10)) (7.0.0)\u001b[0m\n",
      "\u001b[34mCollecting py-cpuinfo (from deepspeed==0.15.4->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 10)) (2.10.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from deepspeed==0.15.4->-r requirements.txt (line 10)) (4.66.5)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-ml-py (from deepspeed==0.15.4->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 2)) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 2)) (0.29.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 2)) (6.0.2)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 2)) (2.32.3)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 2)) (0.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (2025.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 4)) (2.2.3)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from torch->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting av (from qwen_vl_utils->-r requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34mDownloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.2.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting propcache>=0.2.0 (from aiohttp->datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.17.0 (from aiohttp->datasets->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.15.4->-r requirements.txt (line 10)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0.0->deepspeed==0.15.4->-r requirements.txt (line 10)) (2.27.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 2)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2025.1.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 4)) (2025.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 4)) (1.17.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 34.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 51.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.0/76.0 MB 143.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.15.1-py3-none-any.whl (411 kB)\u001b[0m\n",
      "\u001b[34mDownloading qwen_vl_utils-0.0.10-py3-none-any.whl (6.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl (116 kB)\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 168.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 792.7/792.7 kB 109.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 197.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.7/39.7 MB 168.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\u001b[0m\n",
      "\u001b[34mDownloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\u001b[0m\n",
      "\u001b[34mDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\u001b[0m\n",
      "\u001b[34mDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (238 kB)\u001b[0m\n",
      "\u001b[34mDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: deepspeed\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for deepspeed: filename=deepspeed-0.15.4-py3-none-any.whl size=1527834 sha256=24c99213aabea7ed45cd8a90955b303f21b28d892a98810684eadb792b840f44\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9f/b7/07/035dfeaae31b5766822083a749891e45aab9c72d25a78b7dd0\u001b[0m\n",
      "\u001b[34mSuccessfully built deepspeed\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sentencepiece, py-cpuinfo, nvidia-ml-py, hjson, xxhash, regex, propcache, ninja, multidict, msgpack, fsspec, frozenlist, dill, av, aiohappyeyeballs, yarl, qwen_vl_utils, multiprocess, aiosignal, tokenizers, deepspeed, bitsandbytes, aiohttp, transformers, peft, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2025.3.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2025.3.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2025.3.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: dill\u001b[0m\n",
      "\u001b[34mFound existing installation: dill 0.3.9\u001b[0m\n",
      "\u001b[34mUninstalling dill-0.3.9:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled dill-0.3.9\u001b[0m\n",
      "\u001b[34mAttempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34mFound existing installation: multiprocess 0.70.17\u001b[0m\n",
      "\u001b[34mUninstalling multiprocess-0.70.17:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled multiprocess-0.70.17\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mpathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\u001b[0m\n",
      "\u001b[34mpathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 av-14.2.0 bitsandbytes-0.45.4 datasets-3.5.0 deepspeed-0.15.4 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 hjson-3.1.0 msgpack-1.1.0 multidict-6.3.2 multiprocess-0.70.16 ninja-1.11.1.4 nvidia-ml-py-12.570.86 peft-0.15.1 propcache-0.3.1 py-cpuinfo-9.0.0 qwen_vl_utils-0.0.10 regex-2024.11.6 sentencepiece-0.2.0 tokenizers-0.21.1 transformers-4.50.3 xxhash-3.5.0 yarl-1.18.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:07,695 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:07,695 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:07,839 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:07,974 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:08,095 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:08,103 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4de.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hf_token\": \"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\",\n",
      "        \"s3_output\": \"s3://llama-training-s3/llama-training-s3/quantized/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4de.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2025-04-04-06-48-21-030\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://llama-training-s3/pytorch-training-2025-04-04-06-48-21-030/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"quantize_llm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4de.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4de.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"quantize_llm.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hf_token\":\"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\",\"s3_output\":\"s3://llama-training-s3/llama-training-s3/quantized/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=quantize_llm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4de.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p4de.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=quantize_llm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://llama-training-s3/pytorch-training-2025-04-04-06-48-21-030/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p4de.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hf_token\":\"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\",\"s3_output\":\"s3://llama-training-s3/llama-training-s3/quantized/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2025-04-04-06-48-21-030\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://llama-training-s3/pytorch-training-2025-04-04-06-48-21-030/source/sourcedir.tar.gz\",\"module_name\":\"quantize_llm\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4de.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"quantize_llm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hf_token\",\"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\",\"--s3_output\",\"s3://llama-training-s3/llama-training-s3/quantized/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_S3_OUTPUT=s3://llama-training-s3/llama-training-s3/quantized/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 quantize_llm.py --hf_token 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 --s3_output s3://llama-training-s3/llama-training-s3/quantized/model\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:08,104 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-04-04 06:58:08,104 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mCloning into 'AutoAWQ'...\u001b[0m\n",
      "\u001b[34mObtaining file:///opt/ml/code/AutoAWQ\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers>=4.45.0 in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (4.50.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (0.21.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (1.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=2.20 in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (0.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface_hub>=0.26.5 in /opt/conda/lib/python3.11/site-packages (from autoawq==0.2.8) (0.29.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (3.17.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (19.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (2.2.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (2.32.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (4.66.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.20->autoawq==0.2.8) (2024.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (3.11.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.8) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.45.0->autoawq==0.2.8) (2024.11.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.45.0->autoawq==0.2.8) (0.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->autoawq==0.2.8) (7.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->autoawq==0.2.8) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->autoawq==0.2.8) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->autoawq==0.2.8) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->autoawq==0.2.8) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (1.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (6.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (0.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.8) (1.18.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.8) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.8) (3.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.8) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.8) (2025.1.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->autoawq==0.2.8) (3.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.20->autoawq==0.2.8) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.20->autoawq==0.2.8) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.20->autoawq==0.2.8) (2025.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.20->autoawq==0.2.8) (1.17.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: autoawq\u001b[0m\n",
      "\u001b[34mDEPRECATION: Legacy editable install of autoawq==0.2.8 from file:///opt/ml/code/AutoAWQ (setup.py develop) is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\n",
      "\u001b[34mRunning setup.py develop for autoawq\u001b[0m\n",
      "\u001b[34mSuccessfully installed autoawq-0.2.8\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.37.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.38.0,>=1.37.11 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.37.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.11.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.38.0,>=1.37.11->boto3) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.38.0,>=1.37.11->boto3) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.11->boto3) (1.17.0)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.50.3\u001b[0m\n",
      "\u001b[34mUsing cached transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\u001b[0m\n",
      "\u001b[34mCollecting filelock (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.26.0 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting numpy>=1.17 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20.0 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyyaml>=5.1 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mUsing cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.22,>=0.21 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mUsing cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.4.3 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.27 (from transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting charset-normalizer<4,>=2 (from requests->transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna<4,>=2.5 (from requests->transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading idna-3.10-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting urllib3<3,>=1.21.1 (from requests->transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting certifi>=2017.4.17 (from requests->transformers==4.50.3)\u001b[0m\n",
      "\u001b[34mDownloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\u001b[0m\n",
      "\u001b[34mUsing cached transformers-4.50.3-py3-none-any.whl (10.2 MB)\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\u001b[0m\n",
      "\u001b[34mDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 176.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading packaging-24.2-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 763.0/763.0 kB 87.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mUsing cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\u001b[0m\n",
      "\u001b[34mUsing cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34mDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mDownloading requests-2.32.3-py3-none-any.whl (64 kB)\u001b[0m\n",
      "\u001b[34mDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\u001b[0m\n",
      "\u001b[34mDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\u001b[0m\n",
      "\u001b[34mDownloading idna-3.10-py3-none-any.whl (70 kB)\u001b[0m\n",
      "\u001b[34mDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\u001b[0m\n",
      "\u001b[34mDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\u001b[0m\n",
      "\u001b[34mAttempting uninstall: urllib3\u001b[0m\n",
      "\u001b[34mFound existing installation: urllib3 1.26.19\u001b[0m\n",
      "\u001b[34mUninstalling urllib3-1.26.19:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled urllib3-1.26.19\u001b[0m\n",
      "\u001b[34mAttempting uninstall: typing-extensions\u001b[0m\n",
      "\u001b[34mFound existing installation: typing_extensions 4.12.2\u001b[0m\n",
      "\u001b[34mUninstalling typing_extensions-4.12.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled typing_extensions-4.12.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tqdm\u001b[0m\n",
      "\u001b[34mFound existing installation: tqdm 4.66.5\u001b[0m\n",
      "\u001b[34mUninstalling tqdm-4.66.5:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tqdm-4.66.5\u001b[0m\n",
      "\u001b[34mAttempting uninstall: safetensors\u001b[0m\n",
      "\u001b[34mFound existing installation: safetensors 0.5.3\u001b[0m\n",
      "\u001b[34mUninstalling safetensors-0.5.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled safetensors-0.5.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: regex\u001b[0m\n",
      "\u001b[34mFound existing installation: regex 2024.11.6\u001b[0m\n",
      "\u001b[34mUninstalling regex-2024.11.6:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled regex-2024.11.6\u001b[0m\n",
      "\u001b[34mAttempting uninstall: pyyaml\u001b[0m\n",
      "\u001b[34mFound existing installation: PyYAML 6.0.2\u001b[0m\n",
      "\u001b[34mUninstalling PyYAML-6.0.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled PyYAML-6.0.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: packaging\u001b[0m\n",
      "\u001b[34mFound existing installation: packaging 24.1\u001b[0m\n",
      "\u001b[34mUninstalling packaging-24.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled packaging-24.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: numpy\u001b[0m\n",
      "\u001b[34mFound existing installation: numpy 1.26.4\u001b[0m\n",
      "\u001b[34mUninstalling numpy-1.26.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled numpy-1.26.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: idna\u001b[0m\n",
      "\u001b[34mFound existing installation: idna 3.10\u001b[0m\n",
      "\u001b[34mUninstalling idna-3.10:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled idna-3.10\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2024.12.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2024.12.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2024.12.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: filelock\u001b[0m\n",
      "\u001b[34mFound existing installation: filelock 3.17.0\u001b[0m\n",
      "\u001b[34mUninstalling filelock-3.17.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled filelock-3.17.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: charset-normalizer\u001b[0m\n",
      "\u001b[34mFound existing installation: charset-normalizer 3.4.0\u001b[0m\n",
      "\u001b[34mUninstalling charset-normalizer-3.4.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled charset-normalizer-3.4.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: certifi\u001b[0m\n",
      "\u001b[34mFound existing installation: certifi 2025.1.31\u001b[0m\n",
      "\u001b[34mUninstalling certifi-2025.1.31:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled certifi-2025.1.31\u001b[0m\n",
      "\u001b[34mAttempting uninstall: requests\u001b[0m\n",
      "\u001b[34mFound existing installation: requests 2.32.3\u001b[0m\n",
      "\u001b[34mUninstalling requests-2.32.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled requests-2.32.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.29.3\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.29.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.29.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.21.1\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.21.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.21.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.50.3\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.50.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.50.3\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mdatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[34mnumba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker 2.241.0 requires numpy<2.0,>=1.9.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.1 idna-3.10 numpy-2.2.4 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.50.3 typing-extensions-4.13.1 urllib3-2.3.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34mFetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mFetching 17 files:   6%|▌         | 1/17 [00:00<00:04,  3.52it/s]\u001b[0m\n",
      "\u001b[34mFetching 17 files:  24%|██▎       | 4/17 [00:00<00:01,  6.54it/s]\u001b[0m\n",
      "\u001b[34mFetching 17 files:  41%|████      | 7/17 [00:00<00:01,  9.52it/s]\u001b[0m\n",
      "\u001b[34mFetching 17 files:  41%|████      | 7/17 [00:19<00:01,  9.52it/s]\u001b[0m\n",
      "\u001b[34mFetching 17 files:  47%|████▋     | 8/17 [00:23<00:41,  4.63s/it]\u001b[0m\n",
      "\u001b[34mFetching 17 files: 100%|██████████| 17/17 [00:23<00:00,  1.36s/it]\u001b[0m\n",
      "\u001b[34mUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  7.14it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 21.43it/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  10%|█         | 100/1000 [00:00<00:01, 702.87 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  30%|███       | 300/1000 [00:00<00:00, 1036.67 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  60%|██████    | 600/1000 [00:00<00:00, 1470.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  90%|█████████ | 900/1000 [00:00<00:00, 1588.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 100%|██████████| 1000/1000 [00:00<00:00, 1549.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split:   0%|          | 0/29 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split: 100%|██████████| 29/29 [00:00<00:00, 3224.85 examples/s]\u001b[0m\n",
      "\u001b[34mFilter:   0%|          | 0/100 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter: 100%|██████████| 100/100 [00:00<00:00, 172.04 examples/s]\u001b[0m\n",
      "\u001b[34mFilter: 100%|██████████| 100/100 [00:00<00:00, 171.67 examples/s]\u001b[0m\n",
      "\u001b[34mFirst item from the train split:\u001b[0m\n",
      "\u001b[34m{'image_id': 285, 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7F3A97298F10>, 'width': 375, 'height': 500, 'objects': {'id': [1630], 'area': [95676], 'bbox': [[60.0, 31.0, 204.0, 469.0]], 'category': [0]}}\u001b[0m\n",
      "\u001b[34mTotal calibration samples: 30\u001b[0m\n",
      "\u001b[34mFirst calibration sample:\u001b[0m\n",
      "\u001b[34m[{'role': 'system', 'content': [{'type': 'text', 'text': 'Your task will be he predefined main task.\\n'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500 at 0x7F3A97299610>}, {'type': 'text', 'text': 'Please, perform the main task:'}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': {'id': [1630], 'area': [95676], 'bbox': [[60.0, 31.0, 204.0, 469.0]], 'category': [0]}}]}]\u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mChecking Calibration Content: \u001b[0m\n",
      "\u001b[34m------------------------------\u001b[0m\n",
      "\u001b[34mCalibration Data Summary:\u001b[0m\n",
      "\u001b[34minput_ids: shape=torch.Size([30, 706])\u001b[0m\n",
      "\u001b[34mSample data: [151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]\u001b[0m\n",
      "\u001b[34mattention_mask: shape=torch.Size([30, 706])\u001b[0m\n",
      "\u001b[34mSample data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\u001b[0m\n",
      "\u001b[34mpixel_values: shape=torch.Size([19780, 1176])\u001b[0m\n",
      "\u001b[34mSample data: [0.017942329868674278, 0.061737604439258575, -0.02585294470191002, -0.18643562495708466, 0.864651083946228, 0.9522416591644287, 1.0398322343826294, 0.996036946773529, 0.9814385175704956, 1.0106353759765625]\u001b[0m\n",
      "\u001b[34mimage_grid_thw: shape=torch.Size([30, 3])\u001b[0m\n",
      "\u001b[34mSample data: [1, 36, 26]\u001b[0m\n",
      "\u001b[34mQuantizing model...\u001b[0m\n",
      "\u001b[34mNumber of layers to calibrate: 28\u001b[0m\n",
      "\u001b[34mFirst module before patching:\u001b[0m\n",
      "\u001b[34mQwen2_5_VLDecoderLayer(\n",
      "  (self_attn): Qwen2_5_VLFlashAttention2(\n",
      "    (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "    (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "    (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "    (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "    (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Qwen2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "    (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m------------------\u001b[0m\n",
      "\u001b[34mCatcher triggered!\u001b[0m\n",
      "\u001b[34m------------------\u001b[0m\n",
      "\u001b[34mAWQ:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mAWQ:   4%|▎         | 1/28 [00:27<12:28, 27.71s/it]\u001b[0m\n",
      "\u001b[34mAWQ:   7%|▋         | 2/28 [00:53<11:28, 26.48s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  11%|█         | 3/28 [01:19<10:54, 26.17s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  14%|█▍        | 4/28 [01:47<10:46, 26.94s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  18%|█▊        | 5/28 [02:15<10:30, 27.43s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  21%|██▏       | 6/28 [02:43<10:08, 27.66s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  25%|██▌       | 7/28 [03:11<09:45, 27.88s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  29%|██▊       | 8/28 [03:40<09:19, 27.96s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  32%|███▏      | 9/28 [04:08<08:53, 28.09s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  36%|███▌      | 10/28 [04:36<08:26, 28.13s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  39%|███▉      | 11/28 [05:05<07:59, 28.21s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  43%|████▎     | 12/28 [05:33<07:31, 28.20s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  46%|████▋     | 13/28 [06:01<07:03, 28.25s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  50%|█████     | 14/28 [06:29<06:35, 28.24s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  54%|█████▎    | 15/28 [06:58<06:07, 28.28s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  57%|█████▋    | 16/28 [07:26<05:39, 28.26s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  61%|██████    | 17/28 [07:54<05:11, 28.30s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  64%|██████▍   | 18/28 [08:23<04:42, 28.28s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  68%|██████▊   | 19/28 [08:51<04:14, 28.26s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  71%|███████▏  | 20/28 [09:19<03:46, 28.29s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  75%|███████▌  | 21/28 [09:47<03:17, 28.28s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  79%|███████▊  | 22/28 [10:16<02:49, 28.32s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  82%|████████▏ | 23/28 [10:44<02:21, 28.29s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  86%|████████▌ | 24/28 [11:12<01:53, 28.31s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  89%|████████▉ | 25/28 [11:41<01:24, 28.28s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  93%|█████████▎| 26/28 [12:09<00:56, 28.31s/it]\u001b[0m\n",
      "\u001b[34mAWQ:  96%|█████████▋| 27/28 [12:37<00:28, 28.29s/it]\u001b[0m\n",
      "\u001b[34mAWQ: 100%|██████████| 28/28 [13:06<00:00, 28.34s/it]\u001b[0m\n",
      "\u001b[34mAWQ: 100%|██████████| 28/28 [13:06<00:00, 28.08s/it]\u001b[0m\n",
      "\u001b[34m[2025-04-04 07:12:12,693] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mdf: /root/.triton/autotune\u001b[0m\n",
      "\u001b[34m: No such file or directory\u001b[0m\n",
      "\u001b[34mSaving quantized model at /opt/ml/model/Qwen-2.5-CPPE-5...\u001b[0m\n",
      "\u001b[34mUploading quantized model to s3://llama-training-s3/llama-training-s3/quantized/model...\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/chat_template.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/config.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/generation_config.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/model.safetensors.index.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/preprocessor_config.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/model-00002-of-00002.safetensors to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/merges.txt to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/added_tokens.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/model-00001-of-00002.safetensors to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/vocab.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/special_tokens_map.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/tokenizer.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mUploading /opt/ml/model/Qwen-2.5-CPPE-5/tokenizer_config.json to s3://llama-training-s3/llama-training-s3/quantized\u001b[0m\n",
      "\u001b[34mQuantization complete and uploaded to S3.\u001b[0m\n",
      "\u001b[34m2025-04-04 07:13:04,232 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-04-04 07:13:04,232 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-04-04 07:13:04,232 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-04-04 07:13:12 Uploading - Uploading generated training model\n",
      "2025-04-04 07:13:40 Completed - Training job completed\n",
      "Training seconds: 1254\n",
      "Billable seconds: 1254\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"quantize_llm.py\",\n",
    "    source_dir=\"training_code\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4de.24xlarge\",#\"ml.g5.4xlarge\",  # Change based on needs\n",
    "    framework_version=\"2.5.1\",\n",
    "    py_version=\"py311\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    hyperparameters={\n",
    "        \"s3_output\": s3_output_path,\n",
    "        \"hf_token\": hf_token  # Add your Hugging Face token here\n",
    "    },\n",
    "    output_path=s3_output_path\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "estimator.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf79478-ca56-4a8c-be5d-c31b2e472a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57503cc7-0a13-407e-94e5-78e955b9a029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7d80c98-46ac-4cd6-8627-c70b76699079",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker stop-training-job --training-job-name pytorch-training-2025-04-04-01-58-45-541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3e35065-8c16-4f3d-a5cb-acf281d4c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker stop-training-job --training-job-name pytorch-training-2025-04-04-01-22-27-335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ce383e6-f2c1-4fd6-91bd-ffb6e29137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###KULLM3 AWQ is 04-324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15854414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "bucket = \"your-bucket\"\n",
    "prefix = \"quantized_model/\"\n",
    "\n",
    "# Download all files\n",
    "for obj in s3.list_objects_v2(Bucket=bucket, Prefix=prefix).get(\"Contents\", []):\n",
    "    file_name = obj[\"Key\"].split(\"/\")[-1]\n",
    "    s3.download_file(bucket, obj[\"Key\"], f\"./quantized_model/{file_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
